{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d8cd1886",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "# Core libs\n",
    "!pip install -qU pinecone sentence-transformers transformers accelerate python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "72b2a303",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()  # expects .env with PINECONE_API_KEY=...\n",
    "\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "\n",
    "API_KEY = os.getenv(\"PINECONE_API_KEY\")\n",
    "assert API_KEY, \"PINECONE_API_KEY missing from your .env\"\n",
    "\n",
    "pc = Pinecone(api_key=API_KEY)\n",
    "\n",
    "INDEX_NAME = \"squad-e5-dev\"\n",
    "DIM = 768            # E5-base-v2\n",
    "METRIC = \"cosine\"    # we normalized vectors when building, so cosine is right\n",
    "\n",
    "# Create if not exists\n",
    "if INDEX_NAME not in [i.name for i in pc.list_indexes()]:\n",
    "    pc.create_index(\n",
    "        name=INDEX_NAME,\n",
    "        dimension=DIM,\n",
    "        metric=METRIC,\n",
    "        spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\"),\n",
    "        deletion_protection=\"disabled\",\n",
    "    )\n",
    "\n",
    "index = pc.Index(INDEX_NAME)\n",
    "NAMESPACE = \"squad-dev-v1.1\"   # keep dev/train separate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bbaade50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2099, 11) (2099, 768)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "CHUNKS_CSV = \"../Data/squad_prepared/processed_chunks.csv\"\n",
    "EMBS_NPY   = \"../Data/squad_prepared/embeddings.npy\"\n",
    "\n",
    "chunks = pd.read_csv(CHUNKS_CSV)\n",
    "embs   = np.load(EMBS_NPY)  # shape = (num_chunks, 768)\n",
    "\n",
    "print(chunks.shape, embs.shape)\n",
    "assert embs.shape[1] == DIM, f\"Embedding dim {embs.shape[1]} != {DIM}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fd0317fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upsert complete.\n"
     ]
    }
   ],
   "source": [
    "# You can rerun safely; upsert overwrites by ID.\n",
    "# IDs should be unique. Use your existing chunk_id column if present.\n",
    "\n",
    "BATCH = 200\n",
    "def row_to_item(row, vec):\n",
    "    md = {\n",
    "        \"text\": str(row[\"chunk_text\"]),\n",
    "        \"title\": str(row[\"contract_title\"]) if \"contract_title\" in row else str(row.get(\"title\",\"\")),\n",
    "        \"para_idx\": int(row.get(\"paragraph_index\", -1)),\n",
    "        \"chunk_idx\": int(row.get(\"chunk_index\", -1)),\n",
    "    }\n",
    "    return {\"id\": str(row[\"chunk_id\"]), \"values\": vec.tolist(), \"metadata\": md}\n",
    "\n",
    "vectors = []\n",
    "for i, row in chunks.iterrows():\n",
    "    vectors.append(row_to_item(row, embs[i]))\n",
    "    if len(vectors) == BATCH:\n",
    "        index.upsert(vectors=vectors, namespace=NAMESPACE)\n",
    "        vectors = []\n",
    "if vectors:\n",
    "    index.upsert(vectors=vectors, namespace=NAMESPACE)\n",
    "\n",
    "print(\"Upsert complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f214b79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "e5 = SentenceTransformer(\"intfloat/e5-base-v2\")\n",
    "\n",
    "def encode_query(q: str):\n",
    "    return e5.encode([\"query: \" + q], normalize_embeddings=True, convert_to_numpy=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1efc7ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dense_retrieve(query, topk=30, filt=None, namespace=NAMESPACE):\n",
    "    qv = encode_query(query).tolist()\n",
    "    res = index.query(\n",
    "        vector=qv,\n",
    "        top_k=topk,\n",
    "        include_metadata=True,\n",
    "        namespace=namespace,\n",
    "        filter=filt,\n",
    "    )\n",
    "    return res[\"matches\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2b906e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import CrossEncoder\n",
    "# A strong, fast reranker:\n",
    "reranker = CrossEncoder(\"cross-encoder/ms-marco-MiniLM-L-6-v2\")\n",
    "\n",
    "def retrieve_and_rerank(query, topk_dense=30, topk_final=5, filt=None):\n",
    "    matches = dense_retrieve(query, topk=topk_dense, filt=filt)\n",
    "    pairs = [(query, m[\"metadata\"][\"text\"]) for m in matches]\n",
    "    ce_scores = reranker.predict(pairs)  # array of floats\n",
    "    ranked = sorted(zip(matches, ce_scores), key=lambda x: x[1], reverse=True)[:topk_final]\n",
    "    return [{\n",
    "        \"text\": m[\"metadata\"][\"text\"],\n",
    "        \"title\": m[\"metadata\"].get(\"title\"),\n",
    "        \"dense\": float(m[\"score\"]),\n",
    "        \"ce\": float(s)\n",
    "    } for (m, s) in ranked]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4542e458",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d3e0d399d54494e8b2645da2b454e74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a7790bdfb4042d6a01bde9a7261cd15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/496M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8e59d0c70364c598a9a08fa7607ed06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/79.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2eb562afc2584717aa9965c21af4686c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8b68b188a564461a7775a80b95dfc79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9749f6d80cdf4db78fca27c6ac672123",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/772 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ans='einstein'  (reader=0.934) | CE=3.457 | dense=0.848 | Title=Force\n",
      "→ philosophers in antiquity used the concept of force in the study of stationary and moving objects and simple machines, but thinkers such as aristotle and archimedes retained fundamental errors in understanding force. in part this was due to…\n",
      "\n",
      "Ans='albert einstein'  (reader=0.558) | CE=3.944 | dense=0.833 | Title=Force\n",
      "→ it was only the orbit of the planet mercury that newton's law of gravitation seemed not to fully explain. some astrophysicists predicted the existence of another planet ( vulcan ) that would explain the discrepancies ; however, despite some…\n",
      "\n",
      "Ans='isaac newton'  (reader=0.005) | CE=-0.279 | dense=0.792 | Title=Force\n",
      "→ the development of fundamental theories for forces proceeded along the lines of unification of disparate ideas. for example, isaac newton unified the force responsible for objects falling at the surface of the earth with the force responsib…\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "reader = pipeline(\"question-answering\",\n",
    "                  model=\"deepset/roberta-base-squad2\",\n",
    "                  tokenizer=\"deepset/roberta-base-squad2\")\n",
    "\n",
    "def answer_from_contexts(question, contexts, max_ctx=5):\n",
    "    preds = []\n",
    "    for c in contexts[:max_ctx]:\n",
    "        out = reader(question=question, context=c[\"text\"])\n",
    "        preds.append({\n",
    "            \"title\": c[\"title\"], \"ce\": c[\"ce\"], \"dense\": c[\"dense\"],\n",
    "            \"answer\": out.get(\"answer\",\"\"), \"score\": float(out.get(\"score\",0.0)),\n",
    "            \"context\": c[\"text\"][:240].replace(\"\\n\",\" \") + (\"…\" if len(c[\"text\"])>240 else \"\")\n",
    "        })\n",
    "    return sorted(preds, key=lambda x: x[\"score\"], reverse=True)\n",
    "\n",
    "# Quick sanity test\n",
    "q = \"Who developed the theory of relativity?\"\n",
    "ctx = retrieve_and_rerank(q, topk_dense=30, topk_final=5)\n",
    "preds = answer_from_contexts(q, ctx, max_ctx=5)\n",
    "for p in preds[:3]:\n",
    "    print(f\"Ans={p['answer']!r}  (reader={p['score']:.3f}) | CE={p['ce']:.3f} | dense={p['dense']:.3f} | Title={p['title']}\\n→ {p['context']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c3b0d23b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10570"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "SQUAD_DEV = \"../Data/SQuAD/dev-v1.1.json\"\n",
    "\n",
    "with open(SQUAD_DEV, \"r\", encoding=\"utf-8\") as f:\n",
    "    raw = json.load(f)\n",
    "\n",
    "# Build (q, answers[], title) triples\n",
    "eval_queries = []\n",
    "for art in raw[\"data\"]:\n",
    "    title = art[\"title\"]\n",
    "    for para in art[\"paragraphs\"]:\n",
    "        for qa in para[\"qas\"]:\n",
    "            qtext = qa[\"question\"]\n",
    "            answers = [a[\"text\"] for a in qa[\"answers\"] if a.get(\"text\")]\n",
    "            if qtext and answers:\n",
    "                eval_queries.append((qtext, answers, title))\n",
    "\n",
    "len(eval_queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ce0f4e8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5f7cecb6e3440e7b96cefcbb2354bdd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10570 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@K (string-only): {1: 0.8123935666982025, 3: 0.8727530747398297, 5: 0.8837275307473983, 10: 0.8909176915799433}\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "from tqdm.auto import tqdm\n",
    "def contains_any_answer(text, answers):\n",
    "    t = text.lower()\n",
    "    return any(a.lower() in t for a in answers if a)\n",
    "\n",
    "def eval_retrieval_string_only(queries, ks=(1,3,5,10), per_doc=False):\n",
    "    hits = {k: 0 for k in ks}\n",
    "    total = 0\n",
    "    for q, answers, title in tqdm(queries):\n",
    "        total += 1\n",
    "        if per_doc:\n",
    "            # namespace already isolates the dataset; just rely on rerank top-k\n",
    "            ctxs = retrieve_and_rerank(q, topk_dense=30, topk_final=max(ks))\n",
    "        else:\n",
    "            ctxs = retrieve_and_rerank(q, topk_dense=30, topk_final=max(ks))\n",
    "        first_hit_rank = None\n",
    "        for rank, c in enumerate(ctxs, start=1):\n",
    "            if contains_any_answer(c[\"text\"], answers):\n",
    "                first_hit_rank = rank\n",
    "                break\n",
    "        for k in ks:\n",
    "            if first_hit_rank and first_hit_rank <= k:\n",
    "                hits[k] += 1\n",
    "    return {k: hits[k] / max(1, total) for k in ks}\n",
    "\n",
    "print(\"Recall@K (string-only):\", eval_retrieval_string_only(eval_queries, ks=(1,3,5,10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "62c8874f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ef4be6dadd9498f96f30a5a60d05625",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'EM': 0.717, 'F1': 0.7691748740148737, 'N': 1000}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def normalize_text(s):\n",
    "    s = s.lower()\n",
    "    s = re.sub(r\"\\b(a|an|the)\\b\", \" \", s)\n",
    "    s = re.sub(r\"[^a-z0-9 ]+\", \" \", s)\n",
    "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
    "    return s\n",
    "\n",
    "def em_f1(pred, gold_texts):\n",
    "    pred_n = normalize_text(pred)\n",
    "    gold_ns = [normalize_text(g) for g in gold_texts]\n",
    "    em = max(int(pred_n == g) for g in gold_ns)\n",
    "    def f1_single(p, g):\n",
    "        p_tokens = p.split()\n",
    "        g_tokens = g.split()\n",
    "        common = len(set(p_tokens) & set(g_tokens))\n",
    "        if not p_tokens and not g_tokens: return 1.0\n",
    "        if not common: return 0.0\n",
    "        prec = common / max(1, len(p_tokens))\n",
    "        rec  = common / max(1, len(g_tokens))\n",
    "        return 2 * prec * rec / (prec + rec)\n",
    "    f1 = max(f1_single(pred_n, g) for g in gold_ns) if gold_ns else 0.0\n",
    "    return em, f1\n",
    "\n",
    "def eval_reader(queries, topk_dense=30, topk_final=5):\n",
    "    total, em_sum, f1_sum = 0, 0.0, 0.0\n",
    "    for q, answers, title in tqdm(queries):\n",
    "        ctxs = retrieve_and_rerank(q, topk_dense=topk_dense, topk_final=topk_final)\n",
    "        preds = answer_from_contexts(q, ctxs, max_ctx=topk_final)\n",
    "        pred_ans = preds[0][\"answer\"] if preds else \"\"\n",
    "        em, f1 = em_f1(pred_ans, answers)\n",
    "        em_sum += em\n",
    "        f1_sum += f1\n",
    "        total += 1\n",
    "    return {\"EM\": em_sum/max(1,total), \"F1\": f1_sum/max(1,total), \"N\": total}\n",
    "\n",
    "reader_scores = eval_reader(eval_queries[:1000])  # start with a subset for speed\n",
    "reader_scores"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
